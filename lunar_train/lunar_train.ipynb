{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Creating environment from the given name 'LunarLander-v3'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    \"LunarLander-v3\",\n",
    "    verbose=1,\n",
    "    exploration_final_eps=0.1,\n",
    "    target_update_interval=250,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# âœ… Create environments\n",
    "train_env = gym.make(\"LunarLander-v3\")\n",
    "\n",
    "eval_env = gym.make(\"LunarLander-v3\")\n",
    "\n",
    "# âœ… Setup evaluation callback to save best model\n",
    "eval_callback = EvalCallback(\n",
    "    eval_env,\n",
    "    best_model_save_path=\"./best_model/\",\n",
    "    log_path=\"./logs/\",\n",
    "    eval_freq=10000,\n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    ")\n",
    "\n",
    "# âœ… Create and train model\n",
    "model = DQN(\"MlpPolicy\", train_env, verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=200_000, callback=eval_callback)\n",
    "\n",
    "# âœ… Save final model too (optional)\n",
    "model.save(\"dqn_lunar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¥ Video saved as 'lunar_lander_dqn.mp4'\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "import gymnasium as gym\n",
    "import imageio\n",
    "import numpy as np\n",
    "\n",
    "# âœ… Load trained model\n",
    "model = DQN.load(\"./best_model/best_model\")\n",
    "\n",
    "# âœ… Create env that returns frames\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# âœ… Create video writer\n",
    "video_path = \"lunar_lander_dqn.mp4\"\n",
    "writer = imageio.get_writer(video_path, fps=50, format='FFMPEG')\n",
    "\n",
    "# âœ… Run the agent and write frames\n",
    "for _ in range(1000):\n",
    "    frame = env.render()  # returns RGB array\n",
    "    frame = np.asarray(frame).astype(np.uint8)  # ensure correct type\n",
    "    writer.append_data(frame)\n",
    "\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        obs, _ = env.reset()\n",
    "\n",
    "writer.close()\n",
    "env.close()\n",
    "\n",
    "print(f\"ðŸŽ¥ Video saved as '{video_path}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
